{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from attention import models\n",
    "from attention import utils\n",
    "from attention.vectorizer import Vectorizer\n",
    "from attention.constants import ENGLISH, FRENCH\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SOURCE_DIR = Path('../')\n",
    "DATA_DIR = SOURCE_DIR / 'data'\n",
    "translation_fp = DATA_DIR / 'eng-fra.txt'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer code\n",
    "from attention.data import load_sentences_dataframe, assign_rows_to_split, TranslationDataset, generate_batches\n",
    "from attention.vectorizer import Vectorizer\n",
    "\n",
    "df = load_sentences_dataframe(translation_fp)\n",
    "df = assign_rows_to_split(df, train_ratio=0.3, valid_ratio=0.05, test_ratio=0.65)\n",
    "\n",
    "dataset = TranslationDataset.from_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext.util\n",
    "\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "fasttext.util.download_model('fr', if_exists='ignore')\n",
    "\n",
    "ft_english = fasttext.load_model('cc.en.300.bin')\n",
    "ft_french = fasttext.load_model('cc.fr.300.bin')\n",
    "\n",
    "vectorizer = dataset.vectorizer\n",
    "english_embedding_matrix = vectorizer.build_embedding_matrix_from_fasttext(ft_english, lang=ENGLISH)\n",
    "french_embedding_matrix = vectorizer.build_embedding_matrix_from_fasttext(ft_french, lang=FRENCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from attention.models import Encoder, DecoderRNN, TranslationModel\n",
    "from attention.constants import SEQ_SIZE, SOS_token\n",
    "from attention.utils import normalize_string\n",
    "\n",
    "# build encoder\n",
    "hidden_size = 100\n",
    "encoder = Encoder(english_embedding_matrix, hidden_size)\n",
    "\n",
    "# build decoder\n",
    "output_vocab_size = len(vectorizer.french_vocab)\n",
    "decoder = DecoderRNN(french_embedding_matrix, hidden_size, output_vocab_size)\n",
    "\n",
    "# build model\n",
    "model = TranslationModel(encoder, decoder, output_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Epoch 0 with average training loss of 9.86\n",
      "Completed Epoch 0 with average validation loss of 9.90\n",
      "Completed Epoch 1 with average training loss of 9.85\n",
      "Completed Epoch 1 with average validation loss of 9.90\n",
      "Completed Epoch 2 with average training loss of 9.85\n",
      "Completed Epoch 2 with average validation loss of 9.90\n",
      "Completed Epoch 3 with average training loss of 9.85\n",
      "Completed Epoch 3 with average validation loss of 9.90\n",
      "Completed Epoch 4 with average training loss of 9.85\n",
      "Completed Epoch 4 with average validation loss of 9.90\n",
      "Completed Epoch 5 with average training loss of 9.85\n",
      "Completed Epoch 5 with average validation loss of 9.90\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-57d0d877bc87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnb_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/attention/attention/train.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, nb_epochs, dataset, batch_size, checkpoint)\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mloss_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/attention/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/attention/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from attention.train import Translation_Trainer\n",
    "from attention.utils import handle_dirs\n",
    "from attention.constants import PAD_token\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def loss_func(decoder_outputs, decoder_input):\n",
    "    avg_batch_loss, batch_size = 0, 0\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=vectorizer.english_vocab.lookup_token(PAD_token))\n",
    "    for predicted_seq, actual_seq in zip(decoder_outputs, decoder_input):\n",
    "        avg_batch_loss += criterion(predicted_seq, actual_seq)\n",
    "        batch_size += 1\n",
    "    return avg_batch_loss / batch_size\n",
    "        \n",
    "model_dir = SOURCE_DIR / 'models' / 'simple_rnn'\n",
    "handle_dirs(model_dir)\n",
    "trainer = Translation_Trainer(generate_batches, optimizer, model, model_dir, loss_func, device)\n",
    "\n",
    "nb_epochs = 20\n",
    "trainer.run(nb_epochs, dataset, batch_size=32, checkpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> cinematographique'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from attention.utils import translate\n",
    "\n",
    "english_sent = \"I went to the hospital\"\n",
    "res = translate(english_sent, model, vectorizer)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'moment'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_vocab = vectorizer.french_vocab\n",
    "french_vocab.lookup_index(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21336"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.french_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "sentences = ['I worked on a farm', 'I went to the beach']\n",
    "vectorized_sentences = [vectorizer.vectorize_sentence(sent, language=ENGLISH) for sent in sentences]\n",
    "encoder_inputs = torch.stack(vectorized_sentences)\n",
    "\n",
    "french_vocab = vectorizer.french_vocab\n",
    "sos_token = french_vocab.lookup_token(french_vocab.sos)\n",
    "prediction = model(encoder_inputs, sos_token=sos_token)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention.constants import VALID, ENCODER_INPUT, DECODER_INPUT\n",
    "\n",
    "french_vocab = vectorizer.french_vocab\n",
    "sos_token = french_vocab.lookup_token(french_vocab.sos)\n",
    "\n",
    "dataset.set_split(VALID)\n",
    "gen = generate_batches(dataset, batch_size=32)\n",
    "model.eval()\n",
    "for batch in gen:\n",
    "    encoder_inputs, y_true = batch[ENCODER_INPUT], batch[DECODER_INPUT]\n",
    "    prediction = model(encoder_inputs, sos_token=sos_token)\n",
    "    print(prediction.shape, y_true.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "from attention.models import Encoder, DecoderRNN\n",
    "\n",
    "batch_size = 2\n",
    "seq_size = 10\n",
    "\n",
    "encoder = Encoder(english_embedding_matrix, hidden_size)\n",
    "init_hidden = encoder.init_hidden(batch_size=batch_size, device=device)\n",
    "sentences = ['I worked on a farm', 'I went to the beach']\n",
    "vectorized_sentences = [vectorizer.vectorize_sentence(sent, language=ENGLISH) for sent in sentences]\n",
    "encoder_inputs = torch.stack(vectorized_sentences)\n",
    "encoder_outputs, encoder_hidden = encoder(encoder_inputs, init_hidden)\n",
    "\n",
    "\n",
    "french_vocab = vectorizer.french_vocab\n",
    "decoder = DecoderRNN(\n",
    "    french_embedding_matrix, \n",
    "    hidden_size=hidden_size, \n",
    "    output_size=len(french_vocab)\n",
    ")\n",
    "\n",
    "# decoder_input -> (batch_size, embedding_size) one token at a time \n",
    "sos_token_index = french_vocab.lookup_token(french_vocab.sos)\n",
    "\n",
    "output_size = len(french_vocab)\n",
    "decoder_outputs = torch.zeros(batch_size, seq_size, output_size)\n",
    "next_tokens = torch.tensor(sos_token_index).expand(batch_size)\n",
    "\n",
    "hidden = encoder_hidden\n",
    "for token in range(seq_size-1):\n",
    "    decoder_output, hidden = decoder(next_tokens, hidden)\n",
    "    decoder_outputs[:, token] = decoder_output\n",
    "    next_tokens = torch.argmax(decoder_output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention_env",
   "language": "python",
   "name": "attention_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
