{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "later-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "animal-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "\n",
    "from attention import models\n",
    "from attention import utils\n",
    "from attention.vectorizer import Vectorizer\n",
    "from attention.constants import ENGLISH, FRENCH, SEQ_SIZE, DECODER_INPUT, ENCODER_INPUT, SOS_token\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SOURCE_DIR = Path('../')\n",
    "DATA_DIR = SOURCE_DIR / 'data'\n",
    "translation_fp = DATA_DIR / 'eng-fra.txt'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-regard",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "three-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer code\n",
    "from attention.data import load_sentences_dataframe, assign_rows_to_split, TranslationDataset, generate_batches\n",
    "from attention.vectorizer import Vectorizer\n",
    "\n",
    "df = load_sentences_dataframe(translation_fp)\n",
    "df = assign_rows_to_split(df, train_ratio=0.9, valid_ratio=0.05, test_ratio=0.05)\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "df[ENGLISH] = df[ENGLISH].str.lower()\n",
    "df = df[df[ENGLISH].str.startswith(eng_prefixes)]\n",
    "\n",
    "dataset = TranslationDataset.from_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-ecology",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rocky-investing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "from attention.models import EncoderRNN, DecoderRNN\n",
    "from attention.embeddings import create_spacy_embeddings\n",
    "\n",
    "hidden_size = 256\n",
    "embedding_size = 300\n",
    "english_vocab_size = len(dataset.vectorizer.english_vocab)\n",
    "french_vocab_size = len(dataset.vectorizer.french_vocab)\n",
    "\n",
    "use_pretrained_embeddings = False\n",
    "english_embedding_matrix, french_embedding_matrix = create_spacy_embeddings(dataset.vectorizer)\n",
    "\n",
    "# use pretrained embeddings?\n",
    "if use_pretrained_embeddings:\n",
    "    encoder = EncoderRNN(english_vocab_size, hidden_size, embedding_matrix=english_embedding_matrix)\n",
    "    decoder = DecoderRNN(hidden_size, french_vocab_size, embedding_matrix=french_embedding_matrix)\n",
    "else:\n",
    "    encoder = EncoderRNN(english_vocab_size, hidden_size, embedding_size)\n",
    "    decoder = DecoderRNN(hidden_size, french_vocab_size, embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-graham",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "neither-construction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at 1 epoch is 3.35\n",
      "loss at 2 epoch is 2.94\n",
      "loss at 3 epoch is 2.49\n",
      "loss at 4 epoch is 2.60\n",
      "loss at 5 epoch is 2.74\n",
      "loss at 6 epoch is 2.30\n",
      "loss at 7 epoch is 2.49\n",
      "loss at 8 epoch is 2.43\n",
      "loss at 9 epoch is 2.27\n",
      "loss at 10 epoch is 2.43\n",
      "loss at 11 epoch is 2.22\n",
      "loss at 12 epoch is 2.40\n",
      "loss at 13 epoch is 2.07\n",
      "loss at 14 epoch is 2.27\n",
      "loss at 15 epoch is 2.25\n"
     ]
    }
   ],
   "source": [
    "from attention.train import train_simpleRNN_batch\n",
    "\n",
    "# training params\n",
    "nb_epochs = 15\n",
    "learning_rate = 0.001\n",
    "ignore_index = dataset.vectorizer.english_vocab.lookup_token(dataset.vectorizer.english_vocab.pad)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=ignore_index)\n",
    "batch_size = 32\n",
    "\n",
    "# create optimizers\n",
    "encoder_optim = torch.optim.Adam(encoder.parameters(), learning_rate)\n",
    "decoder_optim = torch.optim.Adam(decoder.parameters(), learning_rate)\n",
    "\n",
    "# run epochs\n",
    "for epoch in range(nb_epochs):\n",
    "    epoch_losses = []\n",
    "    for batch in generate_batches(dataset, batch_size=batch_size):\n",
    "        input_batch, target_batch = batch[ENCODER_INPUT], batch[DECODER_INPUT]\n",
    "        loss = train_simpleRNN_batch(\n",
    "            input_batch, \n",
    "            target_batch, \n",
    "            encoder, \n",
    "            decoder, \n",
    "            encoder_optim, \n",
    "            decoder_optim,\n",
    "            criterion,\n",
    "            device,\n",
    "            use_teacher_forcing=True\n",
    "        )\n",
    "        epoch_losses.append(loss)\n",
    "    avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    print(f'loss at {epoch+1} epoch is {avg_loss:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-logan",
   "metadata": {},
   "source": [
    "# Inference (Translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "destroyed-insurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am only warming up now. => pour l instant je m entraine seulement .\n",
      "you are both in the wrong. => vous etes en train de s .\n",
      "he is said to have died => on le dit qu il n est\n",
      "i am bored out of my mind. => je suis en train de ma parole .\n",
      "i am going to stay here for a couple of days. => je suis etonnee que vous que vous etes la\n",
      "they are out shopping. => elles sont sorties faire les enfants\n",
      "i am afraid he will make a mistake. => je crains qu il commette commette une erreur .\n",
      "we are worried about you. => ce n est pas infirmiere mais docteur\n",
      "he likes to go to work => je suis interesse par ton audace .\n",
      "he is not at all foolish => il n est pas vraiment en difficulte\n"
     ]
    }
   ],
   "source": [
    "from attention.utils import translate_simple_rnn\n",
    "\n",
    "sentences = [\n",
    "    \"i am only warming up now.\",\n",
    "    \"you are both in the wrong.\",\n",
    "    \"he is said to have died\",\n",
    "    \"i am bored out of my mind.\",\n",
    "    \"i am going to stay here for a couple of days.\",\n",
    "    \"they are out shopping.\",\n",
    "    \"i am afraid he will make a mistake.\",\n",
    "    \"we are worried about you.\",\n",
    "    \"he likes to go to work\",\n",
    "    \"he is not at all foolish\"\n",
    "]\n",
    "for sent in sentences:\n",
    "    translation = translate_simple_rnn(sent, encoder, decoder, dataset.vectorizer, device)\n",
    "    print(sent, '=>', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "above-bowling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'je suis interesse par l'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate_simple_rnn('i am interested.', encoder, decoder, dataset.vectorizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-canon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention_env",
   "language": "python",
   "name": "attention_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
