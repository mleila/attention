{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regional-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prepared-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "\n",
    "from attention import models\n",
    "from attention import utils\n",
    "from attention.vectorizer import Vectorizer\n",
    "from attention.constants import ENGLISH, FRENCH, SEQ_SIZE, DECODER_INPUT, ENCODER_INPUT\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SOURCE_DIR = Path('../')\n",
    "DATA_DIR = SOURCE_DIR / 'data'\n",
    "translation_fp = DATA_DIR / 'eng-fra.txt'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-marriage",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "furnished-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer code\n",
    "from attention.data import load_sentences_dataframe, assign_rows_to_split, TranslationDataset, generate_batches\n",
    "from attention.vectorizer import Vectorizer\n",
    "\n",
    "df = load_sentences_dataframe(translation_fp)\n",
    "df = assign_rows_to_split(df, train_ratio=0.9, valid_ratio=0.05, test_ratio=0.05)\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "df[ENGLISH] = df[ENGLISH].str.lower()\n",
    "df = df[df[ENGLISH].str.startswith(eng_prefixes)]\n",
    "\n",
    "dataset = TranslationDataset.from_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-spotlight",
   "metadata": {},
   "source": [
    "# Source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "least-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding_size, embedding_matrix=None):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # embedding layer\n",
    "        if embedding_matrix is None:\n",
    "            self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        else:\n",
    "            embedding_size = embedding_matrix.shape[-1]\n",
    "            self.embedding = nn.Embedding.from_pretrained(embedding_matrix)\n",
    "            \n",
    "        \n",
    "        # rnn layer\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embedding_size=None, embedding_matrix=None):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # embedding layer\n",
    "        if embedding_matrix is None:\n",
    "            self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        else:\n",
    "            embedding_size = embedding_matrix.shape[-1]\n",
    "            self.embedding = nn.Embedding.from_pretrained(embedding_matrix, )\n",
    "            \n",
    "        # rnn layer\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = torch.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "    \n",
    "class SimpleRnn(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(SimpleRnn, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, input_sentence, output_sentence):\n",
    "        hidden = self.encoder.initHidden()\n",
    "        encoder_outputs = torch.zeros(1, SEQ_SIZE, self.encoder.hidden_size)\n",
    "        \n",
    "        for idx in range(SEQ_SIZE-1):\n",
    "            token = input_sentence[idx]\n",
    "            output, hidden = self.encoder(token, hidden)\n",
    "            encoder_outputs[0, idx] = output[-1]\n",
    "\n",
    "        decoder_outputs = torch.zeros(1, SEQ_SIZE-1, self.decoder.output_size)\n",
    "        for idx in range(SEQ_SIZE-1):\n",
    "            token = output_sentence[idx]\n",
    "            output, hidden = self.decoder(token, hidden)\n",
    "            decoder_outputs[0, idx] = output[-1]\n",
    "            \n",
    "        return decoder_outputs, hidden\n",
    "    \n",
    "def train_one_sent(sent, translation, model, optim):\n",
    "    optim.zero_grad()\n",
    "    decoder_outputs, hidden = model(sent, translation)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(decoder_outputs.squeeze(0), translation_sentence[1:])\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# translate\n",
    "def translate(sentence, model, vectorizer, device):\n",
    "    vectorized = vectorizer.vectorize_sentence(sentence, language=ENGLISH).to(device)\n",
    "    french_vocab = vectorizer.french_vocab\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    for idx in range(SEQ_SIZE):\n",
    "        token = vectorized[idx]\n",
    "        _, encoder_hidden = encoder_output, encoder_hidden = encoder(token, encoder_hidden)\n",
    "\n",
    "    decoder_outputs = torch.zeros(1, SEQ_SIZE-1, decoder.output_size)\n",
    "\n",
    "    for idx in range(SEQ_SIZE-1):\n",
    "        token = vectorized[idx]\n",
    "        output, hidden =  decoder(token, encoder_hidden)\n",
    "        decoder_outputs[0, idx] = output[-1]\n",
    "\n",
    "    \n",
    "    indices = torch.argmax(decoder_outputs, dim=-1).squeeze(0)\n",
    "    words = [french_vocab.lookup_index(idx) for idx in indices]\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-occasions",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-partner",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "connected-secret",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext.util\n",
    "\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "fasttext.util.download_model('fr', if_exists='ignore')\n",
    "\n",
    "ft_english = fasttext.load_model('cc.en.300.bin')\n",
    "ft_french = fasttext.load_model('cc.fr.300.bin')\n",
    "\n",
    "vectorizer = dataset.vectorizer\n",
    "english_embedding_matrix = vectorizer.build_embedding_matrix_from_fasttext(ft_english, lang=ENGLISH)\n",
    "french_embedding_matrix = vectorizer.build_embedding_matrix_from_fasttext(ft_french, lang=FRENCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-russian",
   "metadata": {},
   "source": [
    "## spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#!python -m spacy download fr_core_news_md\n",
    "#!python -m spacy download en_core_web_sm\n",
    "\n",
    "spacy_english = spacy.load('en_core_web_sm')\n",
    "spacy_french = spacy.load('fr_core_news_md')\n",
    "\n",
    "vectorizer = dataset.vectorizer\n",
    "english_embedding_matrix = vectorizer.build_embedding_matrix_from_spacy(spacy_english, lang=ENGLISH)\n",
    "french_embedding_matrix = vectorizer.build_embedding_matrix_from_spacy(spacy_french, lang=FRENCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-madison",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "use_pretrained_embeddings = False\n",
    "hidden_size = 256\n",
    "embedding_size = 300\n",
    "english_vocab_size = len(dataset.vectorizer.english_vocab)\n",
    "french_vocab_size = len(dataset.vectorizer.french_vocab)\n",
    "\n",
    "# use pretrained embeddings?\n",
    "if use_pretrained_embeddings:\n",
    "    encoder = EncoderRNN(english_vocab_size, hidden_size, embedding_matrix=english_embedding_matrix)\n",
    "    decoder = DecoderRNN(hidden_size, french_vocab_size, embedding_matrix=french_embedding_matrix)\n",
    "else:\n",
    "    encoder = EncoderRNN(english_vocab_size, hidden_size, embedding_size)\n",
    "    decoder = DecoderRNN(hidden_size, french_vocab_size, embedding_size)\n",
    "\n",
    "\n",
    "# TRAIN\n",
    "model = SimpleRnn(encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-private",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "great-neutral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at 1 epoch is 3.01\n",
      "loss at 2 epoch is 1.98\n",
      "loss at 3 epoch is 1.34\n",
      "loss at 4 epoch is 0.90\n",
      "loss at 5 epoch is 0.62\n",
      "loss at 6 epoch is 0.45\n",
      "loss at 7 epoch is 0.36\n",
      "loss at 8 epoch is 0.30\n",
      "loss at 9 epoch is 0.27\n",
      "loss at 10 epoch is 0.25\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "nb_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# create optimizer\n",
    "optim = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "\n",
    "# run epochs\n",
    "for epoch in range(nb_epochs):\n",
    "    epoch_losses = []\n",
    "    for batch in generate_batches(dataset, batch_size=1):\n",
    "        single_sentence, translation_sentence = batch[ENCODER_INPUT], batch[DECODER_INPUT]\n",
    "        single_sentence = single_sentence.squeeze(0)\n",
    "        translation_sentence = translation_sentence.squeeze(0)\n",
    "        loss = train_one_sent(\n",
    "            single_sentence, \n",
    "            translation_sentence, \n",
    "            model,\n",
    "            optim\n",
    "        )\n",
    "        epoch_losses.append(loss)\n",
    "    avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    print(f'loss at {epoch+1} epoch is {avg_loss:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-curtis",
   "metadata": {},
   "source": [
    "# Inference (Translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "limiting-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vous es parfois si puerile . <pad> <pad> <pad>\n",
      "je trop jeune trop est je <pad> <pad> <pad>\n",
      "il il des il il il il <pad> il\n",
      "elle n elle elle elle elle elle elle elle\n",
      "il elle une une il <eos> <pad> <pad> <pad>\n",
      "je je lisent en je <pad> <pad> <pad> <pad>\n",
      "il il il il il <pad> il il il\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"you are so childish sometimes\",\n",
    "    \"i am too short.\",\n",
    "    \"he is unpopular for some reason\",\n",
    "    \"she is french.\"\n",
    "    \n",
    "    \"this is a new sentence\",\n",
    "    \"I dont like this.\",\n",
    "    \"I love studying math\",\n",
    "    \"he went to school\"\n",
    "]\n",
    "for sent in sentences:\n",
    "    translate(sent, model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "atmospheric-weather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>french</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77646</th>\n",
       "      <td>you are so childish sometimes.</td>\n",
       "      <td>Tu es parfois si puérile.</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39791</th>\n",
       "      <td>she is in need of help.</td>\n",
       "      <td>Elle a besoin d'aide.</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>i am too short.</td>\n",
       "      <td>Je suis trop petit.</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83279</th>\n",
       "      <td>he is unpopular for some reason.</td>\n",
       "      <td>Il est impopulaire pour une raison quelconque.</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>she is french.</td>\n",
       "      <td>Elle est française.</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                english  \\\n",
       "77646    you are so childish sometimes.   \n",
       "39791           she is in need of help.   \n",
       "6496                    i am too short.   \n",
       "83279  he is unpopular for some reason.   \n",
       "5278                     she is french.   \n",
       "\n",
       "                                               french  split  \n",
       "77646                       Tu es parfois si puérile.  train  \n",
       "39791                           Elle a besoin d'aide.  train  \n",
       "6496                              Je suis trop petit.  train  \n",
       "83279  Il est impopulaire pour une raison quelconque.  train  \n",
       "5278                              Elle est française.  train  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention_env",
   "language": "python",
   "name": "attention_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
