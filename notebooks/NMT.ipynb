{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "otherwise-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pharmaceutical-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "\n",
    "from attention import models\n",
    "from attention import utils\n",
    "from attention.vectorizer import Vectorizer\n",
    "from attention.constants import ENGLISH, FRENCH, SEQ_SIZE, DECODER_INPUT, ENCODER_INPUT, SOS_token\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SOURCE_DIR = Path('../')\n",
    "DATA_DIR = SOURCE_DIR / 'data'\n",
    "translation_fp = DATA_DIR / 'eng-fra.txt'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-letters",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "armed-surgery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 7297 records\n"
     ]
    }
   ],
   "source": [
    "# vectorizer code\n",
    "from attention.data import (\n",
    "    load_sentences_dataframe,\n",
    "    filter_by_prefixes, \n",
    "    assign_rows_to_split,\n",
    "     NMTDataset, \n",
    "     generate_batches\n",
    "     )\n",
    "from attention.constants import ENGLISH\n",
    "from attention.text_preprocessing import preprocess_text\n",
    "from attention.vectorizer import Vectorizer\n",
    "\n",
    "# load dataframe\n",
    "df = load_sentences_dataframe(translation_fp)\n",
    "\n",
    "# split dataset\n",
    "df = assign_rows_to_split(df, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15)\n",
    "\n",
    "# preprocess text\n",
    "df[ENGLISH] = df[ENGLISH].apply(preprocess_text)\n",
    "df[FRENCH] = df[FRENCH].apply(preprocess_text)\n",
    "\n",
    "# filter by prefixes to simplify the NMT task\n",
    "eng_prefixes = (\"i am \", \"i m \", \"he is\", \"she is\", \"she s \", \"you are\", \"you re \")\n",
    "df = filter_by_prefixes(df, eng_prefixes, column=ENGLISH)\n",
    "\n",
    "# create dataset\n",
    "dataset = NMTDataset.from_dataframe(df)\n",
    "print(f'dataset has {len(dataset)} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "contemporary-scroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<attention.data.NMTDataset at 0x7fb1c948a730>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.set_split('valid')\n",
    "print(len(dataset))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-bandwidth",
   "metadata": {},
   "source": [
    "# Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "least-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention.models import AttentionModel\n",
    "\n",
    "source_vocab = dataset.vectorizer.source_vocab\n",
    "target_vocab = dataset.vectorizer.target_vocab\n",
    "\n",
    "source_vocab_size = len(source_vocab)\n",
    "target_vocab_size = len(target_vocab)\n",
    "\n",
    "source_embedding_size= 300\n",
    "target_embedding_size = 300\n",
    "\n",
    "encoding_size = 200\n",
    "target_sos_index = target_vocab.sos_index\n",
    "            \n",
    "model = AttentionModel(\n",
    "    source_vocab_size,\n",
    "    source_embedding_size,\n",
    "    target_vocab_size,\n",
    "    target_embedding_size,\n",
    "    encoding_size,\n",
    "    target_sos_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "concrete-harvey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Epoch 0 with average training loss of 3.06\n",
      "Completed Epoch 0 with average validation loss of 3.99\n",
      "Completed Epoch 1 with average training loss of 1.73\n",
      "Completed Epoch 1 with average validation loss of 3.61\n",
      "Completed Epoch 2 with average training loss of 1.13\n",
      "Completed Epoch 2 with average validation loss of 3.52\n",
      "Completed Epoch 3 with average training loss of 0.79\n",
      "Completed Epoch 3 with average validation loss of 3.58\n",
      "Completed Epoch 4 with average training loss of 0.60\n",
      "Completed Epoch 4 with average validation loss of 3.64\n",
      "Completed Epoch 5 with average training loss of 0.48\n",
      "Completed Epoch 5 with average validation loss of 3.60\n",
      "Completed Epoch 6 with average training loss of 0.40\n",
      "Completed Epoch 6 with average validation loss of 3.57\n",
      "Completed Epoch 7 with average training loss of 0.35\n",
      "Completed Epoch 7 with average validation loss of 3.65\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-04ef1f802fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# run training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/attention/attention/train.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, nb_epochs, dataset, batch_size, checkpoint)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mloss_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/attention/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/attention/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from attention.train import Translation_Trainer\n",
    "from attention.utils import handle_dirs\n",
    "from attention.losses import average_loss\n",
    "from attention.data import generate_nmt_batches\n",
    "\n",
    "# training parameters\n",
    "nb_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# create optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "\n",
    "# configure model storage\n",
    "model_id = 'attention_1'\n",
    "model_dir = SOURCE_DIR / f'models_store/{model_id}'\n",
    "handle_dirs(model_dir)\n",
    "\n",
    "# create trainer object\n",
    "tainer = Translation_Trainer(\n",
    "    data_loader=generate_nmt_batches, \n",
    "    optimizer=optimizer, \n",
    "    model=model, \n",
    "    model_dir=model_dir, \n",
    "    loss_func=average_loss, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "# run training\n",
    "tainer.run(nb_epochs, dataset, batch_size, checkpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-matrix",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_attention_rnn(sent, model, vectorizer, device):\n",
    "    data_dict = vectorizer.vectorize(sent, '')\n",
    "    source_vector = torch.tensor(data_dict['source_vector']).unsqueeze(0)\n",
    "    source_length = torch.tensor(data_dict['source_length']).unsqueeze(0)\n",
    "    target_seq = torch.tensor(data_dict['target_x_vector']).unsqueeze(0)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    output = model(source_vector, source_length, target_seq)\n",
    "    sent = torch.argmax(output[:, 0, :], dim=-1)\n",
    "    tokens = []\n",
    "    for index in sent.numpy():\n",
    "        token = vectorizer.target_vocab.lookup_index(index)\n",
    "        if token == '<eos>':\n",
    "            break\n",
    "        tokens.append(token)\n",
    "        \n",
    "    return ' '.join(tokens)\n",
    "    \n",
    "\n",
    "sentences = [\n",
    "    \"i am only warming up now.\",\n",
    "    \"you are both in the wrong.\",\n",
    "    \"he is said to have died\",\n",
    "    \"i am bored out of my mind.\",\n",
    "    \"i am going to stay here for a couple of days.\",\n",
    "    \"they are out shopping.\",\n",
    "    \"i am afraid he will make a mistake.\",\n",
    "    \"we are worried about you.\",\n",
    "    \"he likes to go to work\",\n",
    "    \"he is not at all foolish\",\n",
    "    \"he went to school by bus\",\n",
    "    \"he likes to go shopping\",\n",
    "    \"he loves to play music\",\n",
    "    \"i am happy.\"\n",
    "]\n",
    "for sent in sentences:\n",
    "    translation = translate_attention_rnn(sent, model, dataset.vectorizer, device)\n",
    "    print(sent, '=>', translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention_env",
   "language": "python",
   "name": "attention_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
